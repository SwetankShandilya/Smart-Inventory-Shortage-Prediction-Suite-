{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKPAjJ_2kKGL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPQMb1K7bBYA"
      },
      "outputs": [],
      "source": [
        "file_id = \"1EZ5r0bkx3rDzVU9i1Vsc_ySwRPfj3KLJ\"\n",
        "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "df = pd.read_csv(url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "0aYZlcvPNke3",
        "outputId": "0639919a-ad61-4648-8cd6-eb8c305e19b7"
      },
      "outputs": [],
      "source": [
        "df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ji_lLj_sNrAp",
        "outputId": "8847b3ee-8821-4b38-8b48-73e7e4fd3678"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Sx0JC5vOa3Y"
      },
      "outputs": [],
      "source": [
        "df.rename(columns={'Shortage Qty ': 'Shortage_Qty'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hNUgmt_O3o2",
        "outputId": "9b86bfd2-94e1-4e49-e13e-9db051c71c27"
      },
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jwh-FjNz_S-5"
      },
      "outputs": [],
      "source": [
        "def preprocess_shortage_data(df):\n",
        "\n",
        "    processed_df = df.copy()\n",
        "\n",
        "    required_columns = ['Date', 'Item', 'Shortage_Qty']\n",
        "    if not all(col in processed_df.columns for col in required_columns):\n",
        "        raise ValueError(f\"DataFrame must contain columns: {required_columns}\")\n",
        "\n",
        "    processed_df['Date'] = pd.to_datetime(processed_df['Date'])\n",
        "\n",
        "    min_date = processed_df['Date'].min()\n",
        "    max_date = processed_df['Date'].max()\n",
        "\n",
        "    date_range = pd.date_range(start=min_date, end=max_date)\n",
        "\n",
        "    unique_items = processed_df['Item'].unique()\n",
        "\n",
        "    full_df = pd.DataFrame([(item, date) for item in unique_items for date in date_range],columns=['Item', 'Date'])\n",
        "\n",
        "    full_df = full_df.merge(processed_df, on=['Item', 'Date'], how='left')\n",
        "\n",
        "    full_df['Shortage_Qty'] = full_df['Shortage_Qty'].fillna(0)\n",
        "\n",
        "    full_df['is_shortage'] = (full_df['Shortage_Qty'] > 0).astype(int)\n",
        "\n",
        "    item_shortage_stats = full_df.groupby('Item').agg({\n",
        "        'is_shortage': 'mean',\n",
        "        'Shortage_Qty': [\n",
        "            'count',\n",
        "            'mean',\n",
        "            'max',\n",
        "            'sum'\n",
        "        ]\n",
        "    }).reset_index()\n",
        "\n",
        "    item_shortage_stats.columns = [\n",
        "        'Item',\n",
        "        'historical_shortage_prob',\n",
        "        'total_observations',\n",
        "        'avg_shortage_qty',\n",
        "        'max_shortage_qty',\n",
        "        'total_shortage_qty'\n",
        "    ]\n",
        "\n",
        "    full_df = full_df.merge(item_shortage_stats, on='Item', how='left')\n",
        "\n",
        "    def generate_time_features(group):\n",
        "\n",
        "        group = group.sort_values('Date')\n",
        "\n",
        "        group['shortage_qty_7d_avg'] = group['Shortage_Qty'].rolling(window=7, min_periods=1).mean().shift(1)\n",
        "        group['shortage_qty_30d_avg'] = group['Shortage_Qty'].rolling(window=30, min_periods=1).mean().shift(1)\n",
        "        group['shortage_freq_7d'] = group['is_shortage'].rolling(window=7, min_periods=1).mean().shift(1)\n",
        "        group['shortage_freq_30d'] = group['is_shortage'].rolling(window=30, min_periods=1).mean().shift(1)\n",
        "\n",
        "        return group\n",
        "\n",
        "    full_df = full_df.groupby('Item', group_keys=False).apply(generate_time_features)\n",
        "\n",
        "    full_df['day_of_week'] = full_df['Date'].dt.dayofweek\n",
        "    full_df['month'] = full_df['Date'].dt.month\n",
        "    full_df['quarter'] = full_df['Date'].dt.quarter\n",
        "    full_df['year'] = full_df['Date'].dt.year\n",
        "    full_df['is_weekend'] = full_df['day_of_week'].isin([5, 6]).astype(int)\n",
        "\n",
        "    le = LabelEncoder()\n",
        "    full_df['item_encoded'] = le.fit_transform(full_df['Item'])\n",
        "\n",
        "    features = [\n",
        "        'item_encoded',\n",
        "        'day_of_week',\n",
        "        'month',\n",
        "        'quarter',\n",
        "        'year',\n",
        "        'is_weekend',\n",
        "        'total_observations',\n",
        "        'historical_shortage_prob',\n",
        "        'avg_shortage_qty',\n",
        "        'max_shortage_qty',\n",
        "        'total_shortage_qty',\n",
        "        'shortage_qty_7d_avg',\n",
        "        'shortage_qty_30d_avg',\n",
        "        'shortage_freq_7d',\n",
        "        'shortage_freq_30d'\n",
        "    ]\n",
        "\n",
        "    full_df.dropna(subset=features + ['is_shortage'], inplace=True)\n",
        "    min_len = min(len(full_df[features]), len(full_df['is_shortage']))\n",
        "    x, y = full_df[features].iloc[:min_len], full_df['is_shortage'].iloc[:min_len]\n",
        "\n",
        "\n",
        "    return full_df[features], full_df['is_shortage'], le"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bCpHzwPLMJj3"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, precision_recall_curve, confusion_matrix, classification_report\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZgD7wSeU9s7Q"
      },
      "outputs": [],
      "source": [
        "def train_shortage_models(X, y):\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "    models = {\n",
        "        # 'Logistic Regression': LogisticRegression(max_iter=1000),\n",
        "        # 'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "        # 'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
        "        'Neural Network': MLPClassifier(hidden_layer_sizes=(128, 64), max_iter=100)\n",
        "    }\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for name, model in models.items():\n",
        "\n",
        "        model.fit(X_train_scaled, y_train)\n",
        "        y_pred = model.predict(X_test_scaled)\n",
        "        y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "        results[name] = {\n",
        "            'model': model,\n",
        "            'auc': roc_auc_score(y_test, y_proba),\n",
        "            'accuracy': accuracy_score(y_test, y_pred),\n",
        "            'confusion_matrix': confusion_matrix(y_test, y_pred),\n",
        "            'classification_report': classification_report(y_test, y_pred),\n",
        "            'probabilities': y_proba\n",
        "        }\n",
        "\n",
        "        print(f\"\\n{name} Performance:\")\n",
        "        print(f\"AUC Score: {results[name]['auc']:.4f}\")\n",
        "        print(\"Classification Report:\")\n",
        "        print(results[name]['classification_report'])\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    for name, result in results.items():\n",
        "        precision, recall, _ = precision_recall_curve(y_test, result['probabilities'])\n",
        "        plt.plot(recall, precision, label=f'{name} (AUC = {result[\"auc\"]:.2f})')\n",
        "\n",
        "    plt.title('Precision-Recall Curves')\n",
        "    plt.xlabel('Recall')\n",
        "    plt.ylabel('Precision')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPLsl99T9s36",
        "outputId": "ff948ccd-a8a5-436e-f4b4-e045cf3ca7a5"
      },
      "outputs": [],
      "source": [
        "x, y, label_encoder = preprocess_shortage_data(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PqUJR7yTup0p",
        "outputId": "24231355-e2bb-4b7e-93a8-0f926d01b798"
      },
      "outputs": [],
      "source": [
        "print(x.shape)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YxHE-0wlx_T6"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y), y=y)\n",
        "class_weight_dict = {0: class_weights[0], 1: class_weights[1]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 844
        },
        "id": "a2B7_VD99s0z",
        "outputId": "f18b3375-c0d6-4f05-82ca-cf32f6691d87"
      },
      "outputs": [],
      "source": [
        "results = train_shortage_models(x, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAYHPl3xX39U"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r1jR9qoce2qk"
      },
      "outputs": [],
      "source": [
        "features_df = x.reset_index(drop=True)\n",
        "target_df = y.reset_index(drop=True)\n",
        "concatenated_df = pd.concat([features_df, target_df], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CHU3dNQj80c3",
        "outputId": "d6dc980a-6617-4524-c0cf-53162bb170ee"
      },
      "outputs": [],
      "source": [
        "concatenated_df.tail(50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6NWjittkvqHA"
      },
      "outputs": [],
      "source": [
        "columns_to_keep = [\"item_encoded\", \"total_observations\", \"historical_shortage_prob\", \"avg_shortage_qty\",\"max_shortage_qty\", \"total_shortage_qty\", \"shortage_qty_7d_avg\",\"shortage_qty_30d_avg\", \"shortage_freq_7d\", \"shortage_freq_30d\",\"is_shortage\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WkMRIcTBwjmf"
      },
      "outputs": [],
      "source": [
        "df_sorted = concatenated_df.sort_values(by=[\"year\", \"quarter\", \"month\", \"day_of_week\"], ascending=False)\n",
        "\n",
        "df_latest = df_sorted.drop_duplicates(subset=[\"item_encoded\"])\n",
        "\n",
        "df_fixed_values= df_latest[columns_to_keep]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "bF_oTYw3w2-A",
        "outputId": "a0b9b541-9f27-4617-a011-06bd73915fbd"
      },
      "outputs": [],
      "source": [
        "df_fixed_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1q0tUvGlxvEI"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "# df_fixed_values.to_csv(\"fixed_values.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2tr1HpUxT1S"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def create_sequences_fast(df, target_col, seq_features, static_features, seq_length=30):\n",
        "    \"\"\"Efficiently create sequences for time-series modeling using NumPy operations.\"\"\"\n",
        "\n",
        "    # Convert DataFrame columns to NumPy arrays (MUCH FASTER than using .iloc[] in loop)\n",
        "    seq_data = df[seq_features].values  # Shape: (num_samples, num_seq_features)\n",
        "    static_data = df[static_features].values\n",
        "    labels_data = df[target_col].values\n",
        "\n",
        "    num_samples = len(df) - seq_length\n",
        "    num_seq_features = len(seq_features)\n",
        "    num_static_features = len(static_features)\n",
        "\n",
        "    # Pre-allocate NumPy arrays\n",
        "    sequences = np.zeros((num_samples, seq_length, num_seq_features), dtype=np.float32)\n",
        "    static_inputs = static_data[seq_length:]  # Faster slicing instead of looping\n",
        "    labels = labels_data[seq_length:]\n",
        "\n",
        "    # Vectorized slicing (avoids Python loops)\n",
        "    for i in range(num_samples):\n",
        "        sequences[i] = seq_data[i : i + seq_length]\n",
        "\n",
        "    return sequences, static_inputs, labels\n",
        "seq_features = ['shortage_qty_7d_avg','shortage_qty_30d_avg','shortage_freq_7d','shortage_freq_30d']\n",
        "static_features = ['item_encoded','day_of_week','month','quarter','year','is_weekend','total_observations','historical_shortage_prob','avg_shortage_qty','max_shortage_qty','total_shortage_qty']\n",
        "# Call optimized function\n",
        "X_seq, X_static, y = create_sequences_fast(concatenated_df, target_col=\"is_shortage\", seq_features=seq_features, static_features=static_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XT_CKyVCV8oL"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input, Concatenate\n",
        "from tensorflow.keras.models import Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQKSXToBwCiQ",
        "outputId": "b835e509-b78a-41cc-dce6-4261dc95b70a"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Compute class weights\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight=\"balanced\",\n",
        "    classes=np.unique(y),\n",
        "    y=y\n",
        ")\n",
        "class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
        "y = np.array(y, dtype=np.float32).reshape(-1, 1)  # Ensure correct shape\n",
        "\n",
        "# Train model with class weights\n",
        "model.fit([X_seq, X_static], y, epochs=3, batch_size=32, validation_split=0.2, class_weight=class_weight_dict)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dY-UiAEUKTPb",
        "outputId": "1257a7b3-c308-442b-d611-50f732fcb7ec"
      },
      "outputs": [],
      "source": [
        "# Get model predictions\n",
        "y_pred_probs = model.predict([X_seq, X_static])  # Probabilities\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)  # Convert to binary labels\n",
        "\n",
        "# Filter cases where the actual value is 1\n",
        "y_true_shortages = Y[Y == 1]\n",
        "y_pred_shortages = y_pred[Y == 1]\n",
        "y_pred_probs_shortages = y_pred_probs[Y == 1]  # Probabilities for ROC AUC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LBgF58CgB8J",
        "outputId": "02ee0869-6b13-4b2f-f0c9-2d3d58eae375"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "precision_shortage = precision_score(y_true_shortages, y_pred_shortages)\n",
        "recall_shortage = recall_score(y_true_shortages, y_pred_shortages)\n",
        "\n",
        "print(f\"ðŸ”¹ Precision (Shortages): {precision_shortage:.4f}\")\n",
        "print(f\"ðŸ”¹ Recall (Shortages): {recall_shortage:.4f}\")\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "f1_shortage = f1_score(y_true_shortages, y_pred_shortages)\n",
        "print(f\"ðŸ”¹ F1 Score (Shortages): {f1_shortage:.4f}\")\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "auc_shortage = roc_auc_score(y_true_shortages, y_pred_probs_shortages)\n",
        "print(f\"ðŸ”¹ AUC (Shortages): {auc_shortage:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "omDXxcUhLQcO"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "model_high_precision = XGBClassifier(\n",
        "    scale_pos_weight=0.5,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.05,\n",
        "    eval_metric=\"aucpr\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "d65wtjixOozq",
        "outputId": "f958cdda-2f53-48e5-e5e4-94be9d0a9d89"
      },
      "outputs": [],
      "source": [
        "model_high_precision.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JBzlRIYO-H1",
        "outputId": "efc76be6-b24b-4c45-e588-6ce6034bb9c4"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score\n",
        "y_pred_probs = model_high_precision.predict_proba(x_test)[:, 1]\n",
        "y_pred = (y_pred_probs > 0.8).astype(int)  # Set a high threshold for precision\n",
        "precision_shortage = precision_score(y_test, y_pred)\n",
        "print(f\"ðŸ”¹ Precision (Shortages): {precision_shortage:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwGMFyoMPfA3"
      },
      "outputs": [],
      "source": [
        "mask = (y_test == 1)  # Boolean mask where true labels are 1\n",
        "y_true_1 = y_test[mask]\n",
        "y_pred_1 = y_pred[mask]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJXRZ5kjQDLz",
        "outputId": "099da076-adcb-41d7-cdbc-1dae7f8f0c9a"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score\n",
        "\n",
        "precision_for_1 = precision_score(y_true_1, y_pred_1)\n",
        "print(f\"Precision when y=1: {precision_for_1:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmThwfi4lwd3",
        "outputId": "88940bf1-b73c-462b-db92-f790af3df1e8"
      },
      "outputs": [],
      "source": [
        "# import joblib\n",
        "\n",
        "# # Save the model\n",
        "# joblib.dump(model_high_precision, \"xgb_model_precision.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jRPLr0ymq_c",
        "outputId": "3cf40ce1-6ff3-40f1-cfa1-101dd53fc4e4"
      },
      "outputs": [],
      "source": [
        "# Ensure Y has the correct length\n",
        "X_seq, X_static, Y = create_sequences_fast(concatenated_df, target_col=\"is_shortage\",seq_features=seq_features, static_features=static_features)\n",
        "\n",
        "print(f\"Fixed Shapes -> X_seq: {X_seq.shape}, X_static: {X_static.shape}, Y: {Y.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0iuFcb9h5-s2"
      },
      "outputs": [],
      "source": [
        "X_seq_train, X_seq_test, X_static_train, X_static_test, y_train, y_test = train_test_split(X_seq, X_static, y, test_size=0.2, random_state=40, stratify=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "smCJCPIHiW8b",
        "outputId": "2a06be0c-01ed-48ad-ad09-95c3712bcae3"
      },
      "outputs": [],
      "source": [
        "seq_input = Input(shape=(30, len(seq_features)), name=\"sequence_input\")\n",
        "X = LSTM(64, return_sequences=True)(seq_input)\n",
        "X = Dropout(0.2)(X)\n",
        "X = LSTM(32)(X)\n",
        "\n",
        "# Static Input (Non-Time-Series Features)\n",
        "static_input = Input(shape=(len(static_features),), name=\"static_input\")\n",
        "Y_layer = Dense(32, activation=\"relu\")(static_input)  # Static features go through a Dense layer\n",
        "\n",
        "# Concatenation of Features\n",
        "combined = Concatenate()([X, Y_layer])  # Concatenating features, not labels\n",
        "output = Dense(1, activation=\"sigmoid\")(combined)  # Binary classification output\n",
        "\n",
        "# Model Compilation\n",
        "model = Model(inputs=[seq_input, static_input], outputs=output)\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"AUC\", \"Precision\", \"Recall\"])\n",
        "\n",
        "# Model Summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8IAGINIQFPo",
        "outputId": "1e531000-e28b-41d5-f5b0-8f388669821c"
      },
      "outputs": [],
      "source": [
        "model_high_recall = Model(inputs=[seq_input, static_input], outputs=output)\n",
        "model_high_recall.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"AUC\", \"Precision\", \"Recall\"]\n",
        ")\n",
        "\n",
        "class_weight = {0: 1, 1: 100}  # Higher weight for the minority class\n",
        "model_high_recall.fit([X_seq_train, X_static_train], y_train, epochs=5, batch_size=32, validation_split=0.2, class_weight=class_weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8BQcDxjtjHw",
        "outputId": "a005bb27-93e3-446f-944c-a76f8bcfcf89"
      },
      "outputs": [],
      "source": [
        "model_high_recall.save(\"model_high_recall.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "b8ABIk25vMq_",
        "outputId": "3b274963-0b6b-4953-d2fe-f1fc8f0b5adc"
      },
      "outputs": [],
      "source": [
        " from sklearn.metrics import recall_score\n",
        "\n",
        "# Get predictions on training data\n",
        "y_pred_probs = model_high_recall.predict([X_seq_test, X_static_test])  # Probabilities\n",
        "y_pred = (y_pred_probs > 0.3).astype(int)  # Convert to binary labels with threshold 0.5\n",
        "\n",
        "# Filter only cases where actual y == 1\n",
        "mask = (y_test == 1)\n",
        "y_true_1 = y_test[mask]\n",
        "y_pred_1 = y_pred[mask]\n",
        "\n",
        "# Compute recall\n",
        "recall_for_1 = recall_score(y_true_1, y_pred_1)\n",
        "print(f\"Recall when y=1: {recall_for_1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nSLlFb8svThg"
      },
      "outputs": [],
      "source": [
        "import tensorflow.keras.backend as K\n",
        "\n",
        "def focal_loss(alpha=0.25, gamma=2.0):\n",
        "    def loss(y_true, y_pred):\n",
        "        y_true = K.cast(y_true, K.floatx())\n",
        "        bce = K.binary_crossentropy(y_true, y_pred)\n",
        "        p_t = y_true * y_pred + (1 - y_true) * (1 - y_pred)\n",
        "        return K.mean(alpha * (1 - p_t) ** gamma * bce)\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwcwM70Ab9y9",
        "outputId": "9a69cc89-ac27-4f81-cfec-216d8090da8d"
      },
      "outputs": [],
      "source": [
        "model_f1 = Model(inputs=[seq_input, static_input], outputs=output)\n",
        "model_f1.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=focal_loss(alpha=0.25, gamma=2.0),\n",
        "    metrics=[\"AUC\", \"Precision\", \"Recall\"]\n",
        ")\n",
        "model_f1.fit([X_seq_train, X_static_train], y_train, epochs=5, batch_size=32, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "6HRBOX2GcDjF",
        "outputId": "65e628a1-2211-4bb6-cd6f-9c069d2cbe31"
      },
      "outputs": [],
      "source": [
        "# Get predictions on training data\n",
        "y_pred_probs = model_f1.predict([X_seq_test, X_static_test])  # Probabilities\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)  # Convert to binary labels with threshold 0.5\n",
        "\n",
        "# Filter only cases where actual y == 1\n",
        "mask = (y_test == 1)\n",
        "y_true_1 = y_test[mask]\n",
        "y_pred_1 = y_pred[mask]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygxWGrafeNk_",
        "outputId": "5401382a-0647-4c16-b2c6-f2ce82afc9f6"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import recall_score,precision_score\n",
        "recall_for_1 = recall_score(y_true_1, y_pred_1)\n",
        "precision_for_1=precision_score(y_true_1, y_pred_1)\n",
        "print(f\"Recall when y=1: {recall_for_1:.4f}\")\n",
        "print(f\"Precision when y=1: {precision_for_1:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIQmixCplW3g",
        "outputId": "6657746e-a264-4d34-8522-1cac67a791f2"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "import joblib\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load models\n",
        "recall_model = load_model('/model_high_recall.h5')\n",
        "precision_model = joblib.load(\"/xgb_model_precision.pkl\")  # XGBClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8m9AgI4vsVcU"
      },
      "outputs": [],
      "source": [
        "features_df = x.reset_index(drop=True)\n",
        "target_df = y.reset_index(drop=True)\n",
        "concatenated_df = pd.concat([features_df, target_df], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPO4CaQqtzUb",
        "outputId": "aae7ba4d-34a4-42e3-c3c3-c6665e5bf696"
      },
      "outputs": [],
      "source": [
        "concatenated_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wXxKHZLKsLQx"
      },
      "outputs": [],
      "source": [
        "def create_sequences_fast_2(df, target_col, seq_features, static_features, seq_length=30):\n",
        "    \"\"\"Efficiently create sequences for LSTM and align with static model input (like XGBoost).\"\"\"\n",
        "\n",
        "    # Convert DataFrame columns to NumPy arrays\n",
        "    seq_data = df[seq_features].values\n",
        "    static_data = df[static_features].values\n",
        "    labels_data = df[target_col].values\n",
        "\n",
        "    num_samples = len(df) - seq_length\n",
        "    num_seq_features = len(seq_features)\n",
        "\n",
        "    # Pre-allocate arrays\n",
        "    sequences = np.zeros((num_samples, seq_length, num_seq_features), dtype=np.float32)\n",
        "    static_inputs = static_data[seq_length:]   # Aligned static inputs\n",
        "    labels = labels_data[seq_length:]          # Aligned targets\n",
        "\n",
        "    # Vectorized sequence slicing\n",
        "    for i in range(num_samples):\n",
        "        sequences[i] = seq_data[i : i + seq_length]\n",
        "\n",
        "    return sequences, static_inputs, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BbwXnBlttKx2"
      },
      "outputs": [],
      "source": [
        "seq_features = ['shortage_qty_7d_avg','shortage_qty_30d_avg','shortage_freq_7d','shortage_freq_30d']\n",
        "static_features = ['item_encoded','day_of_week','month','quarter','year','is_weekend','total_observations','historical_shortage_prob','avg_shortage_qty','max_shortage_qty','total_shortage_qty']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WbIF1qNDsMYV"
      },
      "outputs": [],
      "source": [
        "X_seq, X_static, y_aligned = create_sequences_fast_2(concatenated_df, \"is_shortage\",seq_features, static_features, 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96vetvgZ1ok0",
        "outputId": "93c4042f-f9c7-481f-bf4d-9f7c414ac19d"
      },
      "outputs": [],
      "source": [
        "X_static.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2r4cZsY0SE0"
      },
      "outputs": [],
      "source": [
        "# Calculate the number of valid samples generated from sequence creation\n",
        "seq_length = 30  # Or whatever you used\n",
        "start_idx = seq_length  # The first (seq_length) rows are dropped during sequence creation\n",
        "\n",
        "# Extract aligned rows from the original DataFrame\n",
        "x_xgb_df = concatenated_df.iloc[start_idx:][xgb_features].reset_index(drop=True)\n",
        "\n",
        "# Confirm shape: should be the same as X_seq, X_static, y_aligned\n",
        "assert len(x_xgb_df) == len(X_static), f\"Shape mismatch: {len(x_xgb_df)} != {len(X_static)}\"\n",
        "\n",
        "# Convert to NumPy\n",
        "x_xgb = x_xgb_df.values  # Shape: (1642221, 15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjxMk8mBzk4X"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "indices = np.arange(len(x_xgb))  # Should be 1642221\n",
        "train_idx, test_idx = train_test_split(indices, test_size=0.2, stratify=y_aligned, random_state=42)\n",
        "\n",
        "# Split for XGBoost\n",
        "x_xgb_train = x_xgb[train_idx]\n",
        "x_xgb_test = x_xgb[test_idx]\n",
        "\n",
        "# Split for LSTM\n",
        "X_seq_train, X_seq_test = X_seq[train_idx], X_seq[test_idx]\n",
        "X_static_train, X_static_test = X_static[train_idx], X_static[test_idx]\n",
        "\n",
        "# Labels\n",
        "y_train, y_test = y_aligned[train_idx], y_aligned[test_idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HH1_rjNRrR9v",
        "outputId": "fd434ea0-8522-492e-931e-ad4a7e3f98f6"
      },
      "outputs": [],
      "source": [
        "proba_recall = recall_model.predict([X_seq_test, X_static_test], batch_size=512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypIbFLVQy_Hr"
      },
      "outputs": [],
      "source": [
        "proba_precision = precision_model.predict_proba(x_xgb_test)[:, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGKjZDT9nthL",
        "outputId": "b873c489-d302-4e58-e27b-bd92530b596f"
      },
      "outputs": [],
      "source": [
        "combined_proba = (proba_recall.flatten() + proba_precision) / 2\n",
        "\n",
        "final_pred = (combined_proba > 0.60).astype(int)\n",
        "\n",
        "print(classification_report(y_test, final_pred, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifrPpXbA424D",
        "outputId": "daa26f18-2739-4454-faba-095cf542f445"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model(\"/model_high_recall.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMIyXp7S5Z-S"
      },
      "outputs": [],
      "source": [
        "X_seq, X_static, Y = create_sequences_fast(concatenated_df, target_col=\"is_shortage\",seq_features=seq_features, static_features=static_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bywXBRxc58nR",
        "outputId": "11f9dc29-75b7-46f9-fbb8-7794a71a99ba"
      },
      "outputs": [],
      "source": [
        "y_pred_probs = model.predict([X_seq, X_static])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3M1zH1-U59UP",
        "outputId": "f426dc4c-012f-44f4-9085-bbbf6781e99b"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "thresholds = [0.4,0.41,0.42,0.43,0.44,0.45,0.451,0.46,0.47,0.48,0.49,0.5]\n",
        "\n",
        "for thresh in thresholds:\n",
        "    print(f\"\\n--- Threshold = {thresh} ---\")\n",
        "    y_pred_class = (y_pred_probs > thresh).astype(int)\n",
        "    print(classification_report(y, y_pred_class, digits=4))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
